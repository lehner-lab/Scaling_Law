# Raw sequencing files


In this document, I explain the code found in [001a\_download\_raw\_files.sh](001a_download_raw_files.sh) and [001b\_process\_raw\_files.sh](001b_process_raw_files.sh). All the code in this document is written in bash. To run the code written in this document, you'll also need the 
`Samples_ID.txt` file found in the `Data` folder.


## 1. Source of data

To compare exon levels of inclusion in MDS patients with WT copies of the [SF3B1](https://www.genecards.org/cgi-bin/carddisp.pl?gene=SF3B1) splicing factor with exon inclusion in patients with mutations in SF3B1 we looked at the data generated by [Dolatshad et al, 2015](https://www.nature.com/articles/leu2014331).


## 2. Download files

The raw RNA-seq datasets are stored in GEO. The easiest way to download GEO data is to use the [SRA toolkit](https://www.ncbi.nlm.nih.gov/sra/docs/toolkitsoft/). First, I built a table linking the GSM IDs I had to the SRA IDs required by the SRA toolkit:

```bash
# Make SRR-to-GSM table
wget ftp://ftp.ncbi.nlm.nih.gov/sra/reports/Metadata/SRA_Accessions.tab
grep ^SRR SRA_Accessions.tab | grep GSM | awk 'BEGIN {FS="\t"; print "GSM" FS "SRR"}; {print $10 FS $1}' > GSM_SRR.txt
rm SRA_Accessions.tab
```
With this table, I extracted the sample SRA IDs and prefetched the files:

```bash
# prefetch SRR files from GEO
while IFS=$'\t' read -r -a myArray
do
	SRR_ID=$(grep ${myArray[0]} GSM_SRR.txt | cut -f 2)
	prefetch -v $SRR_ID
done < Data/Sample_IDs.txt
```
The next step involves extracting the fastq files. I extracted them to a folder called `fastq_files` in the current working directory, but feel free to replace this with something else. By default, the files prefetched in the previous step are stored in `~/ncbi/public/sra/`, but if you saved them elsewhere, then this directory should also be changed in the code below:

```bash
# extract fastq files
while IFS=$'\t' read -r -a myArray
do
	SRR_ID=$(grep ${myArray[0]} GSM_SRR.txt | cut -f 2)
	fastq-dump --outdir fastq_files/ --split-files ~/ncbi/public/sra/${SRR_ID}.sra
done < Data/Sample_IDs.txt
```
Finally, I changed the name of the fastq files to the sample name since that is more meaningful:

```bash
# rename files
while IFS=$'\t' read -r -a myArray
do
	SRR_ID=$(grep ${myArray[0]} GSM_SRR.txt | cut -f 2)
	mv fastq_files/${SRR_ID}_1.fastq fastq_files/${myArray[1]}_1.fastq
	mv fastq_files/${SRR_ID}_2.fastq fastq_files/${myArray[1]}_2.fastq
done < Data/Sample_IDs.txt
```


## 3. Process files with VAST-TOOLS

To process the raw sequencing files and extract genomewide exon inclusion levels (as well as information about other alternative splicing events), I used [VAST-TOOLS](https://github.com/vastgroup/vast-tools). The first step in the VAST-TOOLS pipeline is the alignment. This can take quite a bit of time, which is why I recommend using multiple cores if possible. The second step is `combine` and should be fairly quick.

```bash
# run vast-tools
while IFS=$'\t' read -r -a myArray
do
	# make a directory for each sample and go inside
	mkdir ${myArray[1]}
	cd ${myArray[1]}
	
	# store the path to the fastq files we want to process
	FILE1=../fastq_files/${myArray[1]}_1.fastq
	FILE2=../fastq_files/${myArray[1]}_2.fastq
	
	# run vast-tools align
	vast-tools align $FILE1 $FILE2 --sp Hsa -c 10   # using 10 cores
	# run vast-tools combine
	vast-tools combine -o vast_out -sp Hsa
	
	# move back up before creating a directory for the next sample
	cd ..
done < Data/Sample_IDs.txt
```


## 4. Build table to use in downstream analysis

The output of `vast-tools combine` has [many columns](https://github.com/vastgroup/vast-tools#combine-output-format). I removed some of them which I was not interested in, and I also changed the quality scores column. If the quality of an event was `LOW` or better, I set the event as a `Pass`. Otherwise, I called it a `Fail`.

```bash
# for each sample, remove columns I don't want AND say whether quality is overall good ('Pass') or bad ('Fail')
for i in `seq 1 12`; do
	# save sample name as a variable
	SAMPLE=$(head -n $i Data/Sample_IDs.txt | tail -n 1 | cut -f 2)
	
	# move into this sample's directory
	cd $SAMPLE
	
	# select columns I want to keep AND change the value of the quality score column to either 'Pass' or 'Fail'
	cut -f 1,2,4,7,8 vast_out/INCLUSION_LEVELS_FULL-Hsa1-hg19.tab | head -n 1 | awk '{print $0}' > INCLUSION_LEVELS_TRIMMED.tab
	tail -n +2 vast_out/INCLUSION_LEVELS_FULL-Hsa1-hg19.tab | awk 'BEGIN{OFS="\t"}{
		if ($8 ~ /^(SOK|OK|LOW),(SOK|OK|LOW),(SOK|OK|LOW|NA),/ )
			print $1 OFS $2 OFS $4 OFS $7 OFS "Pass";
		else
			print $1 OFS $2 OFS $4 OFS $7 OFS "Fail";
		}' >> INCLUSION_LEVELS_TRIMMED.tab
	
	# move back up before working on the next sample
	cd ..
done
```
After trimming (removing unwanted columns) the files and modifying the quality score column, I merged all the tables into one:

```bash
# take the location of all the trimmed files
for i in `seq 1 12`; do
	SAMPLE=$(head -n $i Sample_IDs.txt | tail -n 1 | cut -f 2)
	SAMPLE_PATH=${SAMPLE}/INCLUSION_LEVELS_TRIMMED.tab
	SAMPLES_ARRAY[i]=${SAMPLE_PATH}
done

# and paste them together
paste -d "\t" ${SAMPLES_ARRAY[@]} | cut -f 1,2,3,4,5,9,10,14,15,19,20,24,25,29,30,34,35,39,40,44,45,49,50,54,55,59,60 > SF3B1wt_SF3B1mut_TABLE.txt
```
Finally, since I was only interested in alternative exon events, I removed all other events for downstream analyses:

```bash
awk 'NR==1 {print}; $2 ~ /^HsaEX/ {print $0}' SF3B1wt_SF3B1mut_TABLE.txt >> Data/SF3B1wt_SF3B1mut_TABLE_EXONS.txt
```
The `SF3B1wt_SF3B1mut_TABLE_EXONS.txt` file produced is provided in the `Data` folder.